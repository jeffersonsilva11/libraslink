# app.py
import streamlit as st
import cv2
import numpy as np
import time
from reconhecedor import ReconhecedorGestosEEmocao

# 1) PÃ¡gina e tÃ­tulo
st.set_page_config(page_title="ğŸ‘‹ Libras Live", layout="wide")
st.title("ğŸ¥ Libras Live â€“ Chat de Gestos e EmoÃ§Ãµes")
st.markdown("Clique em **Iniciar DetecÃ§Ã£o** para abrir a cÃ¢mera e comeÃ§ar a detecÃ§Ã£o.")

# 2) Carrega recursos
@st.cache_resource
def load_resources():
    return ReconhecedorGestosEEmocao(
        model_dir="modelos",
        sequence_length=10,
        threshold=0.6,
        display_mode="sequence"
    )
recognizer = load_resources()

# 3) Placeholders para vÃ­deo, chat e status
video_placeholder = st.empty()
chat_placeholder = st.empty()
status_placeholder = st.empty()

# 4) BotÃµes de controle alinhados
col1, col2 = st.columns(2)
start = col1.button("Iniciar DetecÃ§Ã£o")
stop  = col2.button("Parar DetecÃ§Ã£o")

# 5) Lista de mensagens em memÃ³ria
messages = []

# 6) Loop de captura/OpenCV
# Nota: em simulaÃ§Ã£o de dispositivo (DevTools mobile), cv2.VideoCapture roda no servidor e pode nÃ£o acessar a cÃ¢mera do cliente.
def run_detection():
    cap = cv2.VideoCapture(0)
    status_placeholder.info("Status: Capturando ğŸ“¹")
    while cap.isOpened():
        if stop:
            break
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.flip(frame, 1)
        # DetecÃ§Ã£o leve: a cada 5 frames
        if int(time.time() * 10) % 5 == 0:
            keypoints, _ = recognizer.detectar_keypoints(frame)
            gesture, conf = recognizer.prever_gesto(keypoints)
            emotion, _ = recognizer.detectar_emocao(frame)
            if gesture and conf > recognizer.threshold:
                if not messages or messages[-1]["text"] != gesture:
                    timestamp = time.strftime("%H:%M:%S")
                    messages.append({
                        "text": gesture,
                        "emotion": emotion,
                        "timestamp": timestamp
                    })
        # Exibe vÃ­deo responsivo
        video_placeholder.image(frame, channels="BGR", use_container_width=True)
        # Exibe chat abaixo do vÃ­deo com texto preto
        chat_html = (
            "<div style='height:40vh; overflow-y:auto; border:1px solid #ddd;"
            " padding:8px; border-radius:8px; background:#f8f9fa;'>"
        )
        for msg in messages:
            emoji = "ğŸ˜Š" if msg["emotion"] == "feliz" else "ğŸ˜"
            chat_html += (
                f"<p style='margin:0; padding:4px; color:#000;'>"
                f"<strong>{msg['text']}</strong> {emoji} <em>{msg['timestamp']}</em></p>"
            )
        chat_html += "</div>"
        chat_placeholder.markdown(chat_html, unsafe_allow_html=True)
    cap.release()
    video_placeholder.empty()
    status_placeholder.success("Status: Parado ğŸ›‘")

if start:
    run_detection()
else:
    status_placeholder.info("Status: Aguardando inÃ­cio â³")

# ObservaÃ§Ã£o: Para testar em dispositivos mÃ³veis sem travar, use a versÃ£o com Streamlit-WebRTC.